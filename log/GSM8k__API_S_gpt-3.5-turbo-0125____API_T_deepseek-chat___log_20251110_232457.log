2025-11-10 23:24:57,967 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - data:
  train_batch_size: 256
  micro_batch_size: null
  micro_batch_size_per_gpu: 4
  train_files: ~/data/gsm8k/train.parquet
  val_files: D:\DeepLearning\Code\LangChain\dataset\GSM8k_test_with_prompt4.parquet
  prompt_key: extra_info
  response_key: extra_info
  prompt_dict_keys:
  - question
  response_dict_keys:
  - answer
  multiturn:
    enable: false
    messages_key: messages
    tools_key: tools
    enable_thinking_key: enable_thinking
  max_length: 1024
  truncation: error
  balance_dp_token: false
  chat_template: null
  custom_cls:
    path: null
    name: null
  use_shm: false
  raw_problem_key: extra_info
  first_prompt: raw
  raw_problem_dict_keys:
  - raw_problem
generate:
  max_new_tokens: 1024
model:
  partial_pretrain: ~/models/gemma-1.1-7b-it
  use_shm: false
  fsdp_config:
    model_dtype: fp32
    wrap_policy:
      min_num_params: 0
    cpu_offload: false
    offload_params: false
  external_lib: null
  enable_gradient_checkpointing: true
  trust_remote_code: true
  lora_rank: 8
  lora_alpha: 16
  lora_dropout=0.1: null
  target_modules:
  - q_proj
  - k_proj
  - v_proj
  use_liger: false
  strategy: fsdp2
  log_folder_path: D:\DeepLearning\Code\LangChain\log
  api_name_student: gpt-3.5-turbo-0125
  model_type_student: api
  base_url_student: https://api.apiyi.com/v1
  api_student_key: sk-gB3t5nNqRHAxDjXA9f5a2628AeB44aB7AeE98729B5A1D44d
  temperature_student: 0.7
  max_tokens_student: 4000
  api_name_teacher: deepseek-chat
  model_type_teacher: api
  base_url_teacher: https://api.deepseek.com
  api_teacher_key: sk-063cb38f7e514551a4c4e3dbbeddfe93
  temperature_teacher: 0.2
  max_tokens_teacher: 8000
  api_name_expert: deepseek-chat
  model_type_expert: api
  base_url_expert: http://localhost:11434
  temperature_expert: 0
  max_tokens_expert: 2000
  temperature_summary_model: 0
  max_tokens_summary_model: 2000
optim:
  lr: 1.0e-05
  betas:
  - 0.9
  - 0.95
  weight_decay: 0.01
  warmup_steps_ratio: 0.1
  clip_grad: 1.0
  lr_scheduler: cosine
ulysses_sequence_parallel_size: 1
use_remove_padding: false
trainer:
  default_local_dir: checkpoints/${trainer.project_name}/${trainer.experiment_name}
  default_hdfs_dir: null
  project_name: gsm8k-sft
  experiment_name: test
  total_epochs: 4
  total_training_steps: null
  logger:
  - console
  - wandb
  seed: 1
  save_freq: -1
  test_freq: -1
  nnodes: 2
  n_gpus_per_node: 8
  max_ckpt_to_keep: null
  resume_mode: auto
  resume_from_path: null
  checkpoint:
    save_contents:
    - model
    - optimizer
    - extra
    load_contents: ${trainer.checkpoint.save_contents}
  device: cuda
agent:
  max_samples: 30
  debug_samples: 10
  debug_mode: false
  max_turns: 5
  use_solution_tree: false
  evaluate_multi_solution: false
  conversation_summary: false
  summary_model_name: deepseek-chat
  summary_model_type: api
  summary_base_url: http://localhost:11434
  summary_max_turns: 8
  summary_max_tokens: 1500
  explicit_interaction: true
  parallel_thinking: false
  socratic_teaching: false
  student_sys_prompt: STUDENT_PROMPT_EASY_MISTAKE
  teacher_sys_prompt: TEACHER_PROMPT_EASY
  teacher_tree_sys_prompt: TEACHER_WITH_TREE_PROMPT
  student_tree_sys_prompt: STUDENT_WITH_TREE_PROMPT
  expert_sys_prompt: EXPERT_STUDENT_PROMPT
  use_cognitive_state: true
  carelessness_level: 9
  math_background: beginner
  response_style: brief
  preferred_method: algebraic
  learning_style: reading-writing

2025-11-10 23:25:01,114 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - âœ… å¯¹è¯æ‘˜è¦åŠŸèƒ½å·²ç¦ç”¨
2025-11-10 23:25:01,114 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - âœ… Multi-agent system initialized successfully!
2025-11-10 23:25:01,114 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -    Student: gpt-3.5-turbo-0125
2025-11-10 23:25:01,114 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -    Teacher: deepseek-chat
2025-11-10 23:25:01,114 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -    Expert: Disabled
2025-11-10 23:25:01,114 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -    Cognitive State: Enabled
2025-11-10 23:25:01,114 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -    Solution Tree: Disabled
2025-11-10 23:25:01,114 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -    Mode: Explicit Interaction
2025-11-10 23:25:01,114 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -    Parallel Thinking: False
2025-11-10 23:25:01,114 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -    Socratic Teaching: False
2025-11-10 23:25:01,122 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - 
ðŸŽ¯ å¼€å§‹è§£é¢˜: Solve the following problem step by step. Put your final answer within the \boxed{} command. 

 Janetâ€™s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?
2025-11-10 23:25:01,122 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - ==================================================
2025-11-10 23:25:09,079 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - ðŸ‘¨â€ðŸŽ“ å­¦ç”Ÿ [è½®æ¬¡1]: First, we need to find how many eggs Janet has left to sell after she eats three for breakfast and bakes muffins with four. 

She has 16 eggs per day, eats 3, bakes 4, which leaves her with 16 - 3 - 4 = 9 eggs to sell.

Now, to find out how much she makes at the farmers' market, we multiply the number of eggs she sells by the price per egg: 9 eggs * $2/egg = $18.

Therefore, she makes $\boxed{18}$ dollars every day at the farmers' market.
2025-11-10 23:25:09,094 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - ðŸŽ‰ å­¦ç”Ÿå¾—å‡ºæ­£ç¡®ç­”æ¡ˆ!
2025-11-10 23:26:00,049 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - 
ðŸ“ˆ Student Progress Analysis:
2025-11-10 23:26:00,051 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - Error Reduction: stable
2025-11-10 23:26:00,051 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - Method Improvement: stable
2025-11-10 23:26:00,053 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - Response Quality: stable
2025-11-10 23:26:00,053 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - Turn-by-turn progress:
2025-11-10 23:26:00,055 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -   Turn 1:
2025-11-10 23:26:00,055 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -     Method: computational
2025-11-10 23:26:00,055 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -     Errors: None
2025-11-10 23:26:00,057 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO -     Quality: improved
2025-11-10 23:26:15,274 - D:\DeepLearning\Code\LangChain\v8\utils\evaluator.py - INFO - ðŸ§  Cognitive State Updated - Carelessness: 9 -> 9
