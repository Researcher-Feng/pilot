# visualization_tools.py
"""
å®éªŒç»“æœå¯è§†åŒ–å·¥å…·
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import json
from typing import Dict, List, Any


class ResultVisualizer:
    """å®éªŒç»“æœå¯è§†åŒ–ç±»"""

    def __init__(self, results_file: str):
        self.results_file = results_file
        self.data = self.load_results()

    def load_results(self) -> Dict[str, Any]:
        """åŠ è½½ç»“æœæ–‡ä»¶"""
        with open(self.results_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def create_comprehensive_dashboard(self, output_file: str = "comprehensive_dashboard.png"):
        """åˆ›å»ºç»¼åˆä»ªè¡¨æ¿"""
        fig = plt.figure(figsize=(20, 16))

        # åˆ›å»ºå­å›¾ç½‘æ ¼
        gs = fig.add_gridspec(4, 4)

        # 1. ä¸»è¦æŒ‡æ ‡ï¼ˆå·¦ä¸Šï¼‰
        ax1 = fig.add_subplot(gs[0, :2])
        self._plot_main_metrics(ax1)

        # 2. å¯¹è¯è½®æ¬¡åˆ†å¸ƒï¼ˆå³ä¸Šï¼‰
        ax2 = fig.add_subplot(gs[0, 2:])
        self._plot_turn_distribution(ax2)

        # 3. æ•™å¸ˆæ„å›¾åˆ†æï¼ˆä¸­å·¦ï¼‰
        ax3 = fig.add_subplot(gs[1, :2])
        self._plot_teacher_intents(ax3)

        # 4. æ€è€ƒæ¨¡å¼åˆ†æï¼ˆä¸­å³ï¼‰
        ax4 = fig.add_subplot(gs[1, 2:])
        self._plot_thinking_patterns(ax4)

        # 5. å‡†ç¡®ç‡éšæ—¶é—´å˜åŒ–ï¼ˆä¸‹å·¦ï¼‰
        ax5 = fig.add_subplot(gs[2, :2])
        self._plot_accuracy_progression(ax5)

        # 6. ç­”æ¡ˆæ³„éœ²åˆ†æï¼ˆä¸‹å³ï¼‰
        ax6 = fig.add_subplot(gs[2, 2:])
        self._plot_answer_leakage(ax6)

        # 7. è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼ï¼ˆåº•éƒ¨ï¼‰
        ax7 = fig.add_subplot(gs[3, :])
        self._plot_statistics_table(ax7)

        plt.suptitle('Multi-Agent Math Tutoring System - Comprehensive Analysis',
                     fontsize=16, fontweight='bold', y=0.98)
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.show()

        return output_file

    def _plot_main_metrics(self, ax):
        """ç»˜åˆ¶ä¸»è¦æŒ‡æ ‡"""
        summary = self.data.get('summary', {})

        metrics = ['Accuracy', 'Avg Turns', 'Parallel Thinking', 'Thinking Paths']
        values = [
            summary.get('accuracy', 0),
            summary.get('avg_turns_per_problem', 0),
            summary.get('avg_parallel_thinking', 0),
            summary.get('avg_thinking_paths', 0)
        ]
        colors = ['#2ecc71', '#3498db', '#9b59b6', '#f39c12']

        bars = ax.bar(metrics, values, color=colors, alpha=0.8, edgecolor='black')
        ax.set_title('Key Performance Metrics', fontweight='bold')
        ax.set_ylabel('Value')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2, height + 0.01,
                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')

    def _plot_turn_distribution(self, ax):
        """ç»˜åˆ¶å¯¹è¯è½®æ¬¡åˆ†å¸ƒ"""
        records = self.data.get('records', [])
        turn_counts = [r.get('total_turns', 0) for r in records]

        if turn_counts:
            ax.hist(turn_counts, bins=range(1, max(turn_counts) + 2),
                    alpha=0.7, color='#3498db', edgecolor='black')
            ax.set_title('Distribution of Dialogue Turns', fontweight='bold')
            ax.set_xlabel('Number of Turns')
            ax.set_ylabel('Frequency')

            # æ·»åŠ å¹³å‡çº¿
            avg_turns = np.mean(turn_counts)
            ax.axvline(avg_turns, color='red', linestyle='--',
                       label=f'Average: {avg_turns:.2f}')
            ax.legend()

    def _plot_teacher_intents(self, ax):
        """ç»˜åˆ¶æ•™å¸ˆæ„å›¾åˆ†æ"""
        records = self.data.get('records', [])
        intents = []

        for record in records:
            for turn in record.get('turns', []):
                intent = turn.get('teacher_intent', '')
                if intent:
                    intents.append(intent)

        if intents:
            intent_counts = pd.Series(intents).value_counts()

            # ä½¿ç”¨é¥¼å›¾å±•ç¤º
            wedges, texts, autotexts = ax.pie(
                intent_counts.values,
                labels=intent_counts.index,
                autopct='%1.1f%%',
                startangle=90,
                colors=plt.cm.Set3(np.linspace(0, 1, len(intent_counts)))
            )

            ax.set_title('Teacher Response Intent Distribution', fontweight='bold')

            # ç¾åŒ–æ–‡æœ¬
            for autotext in autotexts:
                autotext.set_color('white')
                autotext.set_fontweight('bold')

    def _plot_thinking_patterns(self, ax):
        """ç»˜åˆ¶æ€è€ƒæ¨¡å¼åˆ†æ"""
        records = self.data.get('records', [])

        parallel_counts = [r.get('parallel_thinking_count', 0) for r in records]
        path_counts = [r.get('thinking_paths_count', 0) for r in records]

        x = range(len(records))
        width = 0.35

        ax.bar([i - width / 2 for i in x], parallel_counts, width,
               label='Parallel Thinking', color='#9b59b6', alpha=0.7)
        ax.bar([i + width / 2 for i in x], path_counts, width,
               label='Thinking Paths', color='#f39c12', alpha=0.7)

        ax.set_title('Thinking Patterns Across Problems', fontweight='bold')
        ax.set_xlabel('Problem Index')
        ax.set_ylabel('Count')
        ax.legend()

        # åªæ˜¾ç¤ºéƒ¨åˆ†xè½´æ ‡ç­¾ä»¥é¿å…æ‹¥æŒ¤
        if len(records) > 10:
            ax.set_xticks(range(0, len(records), max(1, len(records) // 10)))

    def _plot_accuracy_progression(self, ax):
        """ç»˜åˆ¶å‡†ç¡®ç‡éšæ—¶é—´å˜åŒ–"""
        records = self.data.get('records', [])

        if records:
            # è®¡ç®—ç´¯ç§¯å‡†ç¡®ç‡
            correct_count = 0
            cumulative_accuracy = []

            for i, record in enumerate(records):
                if record.get('correct', False):
                    correct_count += 1
                cumulative_accuracy.append(correct_count / (i + 1))

            ax.plot(range(1, len(records) + 1), cumulative_accuracy,
                    marker='o', linewidth=2, markersize=4, color='#2ecc71')
            ax.set_title('Cumulative Accuracy Progression', fontweight='bold')
            ax.set_xlabel('Problem Number')
            ax.set_ylabel('Cumulative Accuracy')
            ax.grid(True, alpha=0.3)
            ax.set_ylim(0, 1)

    def _plot_answer_leakage(self, ax):
        """ç»˜åˆ¶ç­”æ¡ˆæ³„éœ²åˆ†æ"""
        records = self.data.get('records', [])

        leaked = sum(1 for r in records if r.get('leaked_answer', False))
        not_leaked = len(records) - leaked

        categories = ['Leaked Answers', 'No Leakage']
        counts = [leaked, not_leaked]
        colors = ['#e74c3c', '#2ecc71']

        bars = ax.bar(categories, counts, color=colors, alpha=0.8, edgecolor='black')
        ax.set_title('Answer Leakage Analysis', fontweight='bold')
        ax.set_ylabel('Count')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars, counts):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2, height + 0.1,
                    f'{count}', ha='center', va='bottom', fontweight='bold')

    def _plot_statistics_table(self, ax):
        """ç»˜åˆ¶ç»Ÿè®¡è¡¨æ ¼"""
        summary = self.data.get('summary', {})

        # éšè—åæ ‡è½´
        ax.axis('tight')
        ax.axis('off')

        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        table_data = [
            ['Total Problems', summary.get('total_problems', 0)],
            ['Correct Answers', summary.get('correct_answers', 0)],
            ['Accuracy', f"{summary.get('accuracy', 0):.4f}"],
            ['Leaked Answers', summary.get('leaked_answers', 0)],
            ['Leakage Rate', f"{summary.get('answer_leakage_rate', 0):.4f}"],
            ['Avg Turns/Problem', f"{summary.get('avg_turns_per_problem', 0):.2f}"],
            ['Avg Parallel Thinking', f"{summary.get('avg_parallel_thinking', 0):.2f}"],
            ['Avg Thinking Paths', f"{summary.get('avg_thinking_paths', 0):.2f}"]
        ]

        table = ax.table(
            cellText=table_data,
            colLabels=['Metric', 'Value'],
            cellLoc='center',
            loc='center',
            bbox=[0, 0, 1, 1]
        )

        # ç¾åŒ–è¡¨æ ¼
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 1.5)

        # è®¾ç½®æ ‡é¢˜è¡Œæ ·å¼
        for i in range(2):
            table[(0, i)].set_facecolor('#34495e')
            table[(0, i)].set_text_props(weight='bold', color='white')


def create_comparison_visualization(result_files: List[str], labels: List[str],
                                    output_file: str = "comparison_analysis.png"):
    """åˆ›å»ºå¤šå®éªŒå¯¹æ¯”å¯è§†åŒ–"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))

    all_data = []
    for file in result_files:
        with open(file, 'r', encoding='utf-8') as f:
            all_data.append(json.load(f))

    # 1. å‡†ç¡®ç‡å¯¹æ¯”
    accuracies = [data.get('summary', {}).get('accuracy', 0) for data in all_data]
    bars1 = axes[0, 0].bar(labels, accuracies, color='skyblue', alpha=0.7)
    axes[0, 0].set_title('Accuracy Comparison', fontweight='bold')
    axes[0, 0].set_ylabel('Accuracy')
    for bar, acc in zip(bars1, accuracies):
        axes[0, 0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                        f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

    # 2. å¯¹è¯è½®æ¬¡å¯¹æ¯”
    avg_turns = [data.get('summary', {}).get('avg_turns_per_problem', 0) for data in all_data]
    bars2 = axes[0, 1].bar(labels, avg_turns, color='lightgreen', alpha=0.7)
    axes[0, 1].set_title('Average Turns Comparison', fontweight='bold')
    axes[0, 1].set_ylabel('Turns per Problem')
    for bar, turns in zip(bars2, avg_turns):
        axes[0, 1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.1,
                        f'{turns:.2f}', ha='center', va='bottom', fontweight='bold')

    # 3. ç­”æ¡ˆæ³„éœ²ç‡å¯¹æ¯”
    leakage_rates = [data.get('summary', {}).get('answer_leakage_rate', 0) for data in all_data]
    bars3 = axes[0, 2].bar(labels, leakage_rates, color='lightcoral', alpha=0.7)
    axes[0, 2].set_title('Answer Leakage Rate Comparison', fontweight='bold')
    axes[0, 2].set_ylabel('Leakage Rate')
    for bar, rate in zip(bars3, leakage_rates):
        axes[0, 2].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                        f'{rate:.3f}', ha='center', va='bottom', fontweight='bold')

    # 4. å¹¶è¡Œæ€è€ƒå¯¹æ¯”
    parallel_thinking = [data.get('summary', {}).get('avg_parallel_thinking', 0) for data in all_data]
    thinking_paths = [data.get('summary', {}).get('avg_thinking_paths', 0) for data in all_data]

    x = np.arange(len(labels))
    width = 0.35

    bars4a = axes[1, 0].bar(x - width / 2, parallel_thinking, width,
                            label='Parallel Thinking', alpha=0.7)
    bars4b = axes[1, 0].bar(x + width / 2, thinking_paths, width,
                            label='Thinking Paths', alpha=0.7)
    axes[1, 0].set_title('Thinking Patterns Comparison', fontweight='bold')
    axes[1, 0].set_ylabel('Average Count')
    axes[1, 0].set_xticks(x)
    axes[1, 0].set_xticklabels(labels)
    axes[1, 0].legend()

    # 5. æ•™å¸ˆæ„å›¾åˆ†å¸ƒå¯¹æ¯”ï¼ˆç®€åŒ–ç‰ˆï¼‰
    intent_data = []
    for data in all_data:
        intents = []
        for record in data.get('records', []):
            for turn in record.get('turns', []):
                intent = turn.get('teacher_intent', '')
                if intent:
                    intents.append(intent)
        intent_counts = pd.Series(intents).value_counts()
        intent_data.append(intent_counts)

    # é€‰æ‹©å‰3ç§æœ€å¸¸è§çš„æ„å›¾è¿›è¡Œå¯¹æ¯”
    common_intents = set()
    for counts in intent_data:
        common_intents.update(counts.head(3).index)

    for i, intent in enumerate(common_intents):
        intent_values = [counts.get(intent, 0) for counts in intent_data]
        axes[1, 1].bar([f"{label}\n{intent}" for label in labels], intent_values,
                       alpha=0.7, label=intent)

    axes[1, 1].set_title('Common Teacher Intents Comparison', fontweight='bold')
    axes[1, 1].set_ylabel('Count')
    axes[1, 1].tick_params(axis='x', rotation=45)

    # 6. ç»¼åˆè¯„åˆ†ï¼ˆè‡ªå®šä¹‰è¯„åˆ†å…¬å¼ï¼‰
    scores = []
    for data in all_data:
        summary = data.get('summary', {})
        # è¯„åˆ†å…¬å¼ï¼šå‡†ç¡®ç‡æƒé‡æœ€é«˜ï¼Œæ³„éœ²ç‡è´Ÿæƒé‡ï¼Œæ€è€ƒæ¨¡å¼æ­£æƒé‡
        score = (summary.get('accuracy', 0) * 0.5 +
                 (1 - summary.get('answer_leakage_rate', 0)) * 0.3 +
                 min(summary.get('avg_parallel_thinking', 0) * 0.1, 0.1) +
                 min(summary.get('avg_thinking_paths', 0) * 0.1, 0.1))
        scores.append(score)

    bars6 = axes[1, 2].bar(labels, scores, color='gold', alpha=0.7)
    axes[1, 2].set_title('Overall Performance Score', fontweight='bold')
    axes[1, 2].set_ylabel('Score')
    for bar, score in zip(bars6, scores):
        axes[1, 2].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
                        f'{score:.3f}', ha='center', va='bottom', fontweight='bold')

    plt.suptitle('Multi-Experiment Comparison Analysis', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.show()

    return output_file


if __name__ == '__main__':
    # ä½¿ç”¨ç¤ºä¾‹
    print("ğŸ“Š å®éªŒç»“æœå¯è§†åŒ–å·¥å…·")
    print("ä½¿ç”¨æ–¹æ³•:")
    print("1. åˆ›å»ºå•ä¸ªå®éªŒå¯è§†åŒ–:")
    print("   visualizer = ResultVisualizer('results/your_experiment.json')")
    print("   visualizer.create_comprehensive_dashboard()")
    print()
    print("2. åˆ›å»ºå¤šå®éªŒå¯¹æ¯”:")
    print("   create_comparison_visualization(['exp1.json', 'exp2.json'], ['Exp1', 'Exp2'])")