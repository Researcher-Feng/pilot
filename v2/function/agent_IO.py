# agent_IO.py
import os
import sys
sys.path.append(r'/v2/prompt')
sys.path.append(r'/v2/function')
from v2.function import *
from v2.prompt import *
from v2.utils import *
selected_model = 'deepseek-official'
os.environ["OPENAI_API_KEY"] = key_config.get(selected_model, "")
os.environ["OPENAI_BASE_URL"] = key_url
os.environ["DEEPSEEK_API_KEY"] = key_config.get(selected_model, "")
os.environ["DEEPSEEK_BASE_URL"] = ds_key_url
os.environ["LANGSMITH_TRACING"] = "false"
os.environ["LANGSMITH_API_KEY"] = smith_key

from langchain_core.messages import HumanMessage, ToolMessage
from langchain.agents import create_agent
from langchain.agents.middleware import wrap_model_call, wrap_tool_call, dynamic_prompt, ModelRequest, ModelResponse
from langchain.chat_models import init_chat_model
from langchain.agents import AgentState
from langchain.agents.middleware import AgentMiddleware
from typing import Callable


class ModelConfig:
    """ç»Ÿä¸€çš„æ¨¡åž‹é…ç½®ç±»"""

    def __init__(self, model_type: str = "api", **kwargs):
        self.model_type = model_type  # "api" æˆ– "local"
        self.model_name = kwargs.get("model_name", "")
        self.base_url = kwargs.get("base_url", "")
        self.temperature = kwargs.get("temperature", 0.7)
        self.max_tokens = kwargs.get("max_tokens", 2000)
        self.timeout = kwargs.get("timeout", 30)

        # æœ¬åœ°æ¨¡åž‹ç‰¹å®šé…ç½®
        if model_type == "local":
            self.base_url = kwargs.get("base_url", "http://localhost:11434")
            self.extra_params = kwargs.get("extra_params", {})


class SimpleAgent(object):
    """å¢žå¼ºçš„Agentç±»ï¼Œæ”¯æŒå¤šæ¨¡å¼å’Œæœ¬åœ°è°ƒç”¨"""

    def __init__(self, agent_type: str = "student"):
        """åˆå§‹åŒ–agent

        Args:
            agent_type: "student" æˆ– "teacher"
        """
        self.agent_type = agent_type
        self.prompt_sys = None
        self.tools = []
        self.context_schema = None
        self.response_format = None
        self.checkpointer = None
        self.middleware_list = []

        self.agent_config = None
        self.response = None
        self.context = None

        self.middleware_er = None
        self.custom_middleware_er = CustomMiddleware
        self.model = None
        self.agent = None

        # å¤šæ™ºèƒ½ä½“ç³»ç»Ÿé…ç½®
        self.dialogue_history = []
        self.max_turns = 5
        self.current_turn = 0

    def model_init(self, model_config: ModelConfig):
        """åˆå§‹åŒ–æ¨¡åž‹ï¼Œæ”¯æŒAPIå’Œæœ¬åœ°è°ƒç”¨"""
        common_kwargs = {
            "temperature": model_config.temperature,
            "timeout": model_config.timeout,
            "max_tokens": model_config.max_tokens,
        }

        if model_config.model_type == "local":
            # æœ¬åœ°æ¨¡åž‹é…ç½®ï¼ˆå¦‚Ollamaï¼‰
            local_kwargs = {
                "base_url": model_config.base_url,
                **model_config.extra_params,
                **common_kwargs
            }
            self.model = init_chat_model(model_config.model_name, **local_kwargs)
            print(f"âœ… åˆå§‹åŒ–æœ¬åœ°æ¨¡åž‹: {model_config.model_name}")
        else:
            # APIæ¨¡åž‹é…ç½®
            api_kwargs = common_kwargs
            self.model = init_chat_model(model_config.model_name, **api_kwargs)
            print(f"âœ… åˆå§‹åŒ–APIæ¨¡åž‹: {model_config.model_name}")

        self.middleware_er = MiddlewareFunc(self.model, self.model)  # æš‚æ—¶ä½¿ç”¨ç›¸åŒæ¨¡åž‹

    def agent_init(self, prompt_sys_name=None, tools_list=None, context_schema=Context,
                   response_format=ResponseFormat, checkpointer=simple_checkpointer,
                   middleware=None, **kwargs):
        """åˆå§‹åŒ–agenté…ç½®"""
        if prompt_sys_name:
            self.prompt_sys = prompt_sys_name
        if tools_list:
            self.tools = tools_list
        self.context_schema = context_schema
        self.response_format = response_format
        self.checkpointer = checkpointer

        # å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå‚æ•°
        self.max_turns = kwargs.get("max_turns", 5)
        self.parallel_thinking = kwargs.get("parallel_thinking", False)
        self.socratic_teaching = kwargs.get("socratic_teaching", False)
        self.math_background = kwargs.get("math_background", "intermediate")

        if middleware:
            for m in middleware:
                if m == 'dynamic':
                    self.middleware_list.append(self.middleware_er.middleware_dynamic_model_selection())
                elif m == 'handle_tool_errors':
                    self.middleware_list.append(self.middleware_er.middleware_handle_tool_errors())
                elif m == 'user_role_prompt':
                    self.middleware_list.append(self.middleware_er.middleware_user_role_prompt())
                elif m == 'CustomMiddleware':
                    self.middleware_list.append(self.custom_middleware_er())

        self.agent = create_agent(
            model=self.model,
            system_prompt=self.prompt_sys,
            tools=self.tools,
            context_schema=self.context_schema,
            response_format=self.response_format,
            checkpointer=self.checkpointer,
            middleware=self.middleware_list,
        )

    def config_create(self, key_i, value_i):
        self.agent_config = {"configurable": {key_i: value_i}}

    def context_set(self, **kwargs):
        self.context = self.context_schema(**kwargs)

    def chat_once(self, user_input, response_type='invoke', silence=False, **kwargs):
        if response_type == 'invoke':
            self.agent_response_invoke(user_input, **kwargs)
            if not silence:
                self.agent_output()
        else:
            self.agent_response_stream(user_input, **kwargs)

    def multi_agent_chat(self, teacher_agent, problem, **kwargs):
        """å¤šæ™ºèƒ½ä½“å¯¹è¯ - æ˜¾å¼äº¤äº’æ¨¡å¼"""
        print(f"\nðŸŽ¯ å¼€å§‹è§£é¢˜: {problem}")
        print("=" * 50)

        student_response = self._invoke_agent(problem)
        self.dialogue_history.append(("student", student_response))

        for turn in range(self.max_turns):
            print(f"\nðŸ”„ ç¬¬ {turn + 1} è½®å¯¹è¯:")
            print("-" * 30)

            # æ•™å¸ˆå›žåº”
            teacher_input = self._format_teacher_input(problem, self.dialogue_history)
            teacher_response = teacher_agent._invoke_agent(teacher_input)
            self.dialogue_history.append(("teacher", teacher_response))

            print(f"ðŸ‘¨â€ðŸ« æ•™å¸ˆ: {teacher_response}")

            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»“æŸå¯¹è¯
            if self._teacher_end_dialogue(teacher_response):
                print("âœ… æ•™å¸ˆè®¤ä¸ºè§£é¢˜å®Œæˆ")
                break

            # å­¦ç”Ÿå›žåº”
            student_input = self._format_student_input(problem, self.dialogue_history)
            student_response = self._invoke_agent(student_input)
            self.dialogue_history.append(("student", student_response))

            print(f"ðŸ‘¨â€ðŸŽ“ å­¦ç”Ÿ: {student_response}")

            # æ£€æŸ¥å­¦ç”Ÿæ˜¯å¦å¾—å‡ºæ­£ç¡®ç­”æ¡ˆ
            if self._student_end_dialogue(student_response, problem):
                print("ðŸŽ‰ å­¦ç”Ÿå¾—å‡ºæ­£ç¡®ç­”æ¡ˆ!")
                break

            self.current_turn = turn + 1

        return self._get_final_answer()

    def _invoke_agent(self, input_text):
        """è°ƒç”¨agentå¹¶è¿”å›žå“åº”"""
        response = self.agent.invoke({
            "messages": [{"role": "user", "content": input_text}]
        }, config=self.agent_config, context=self.context)

        if response and 'messages' in response:
            return response['structured_response'].main_response
        return ""

    def _format_teacher_input(self, problem, history):
        """æ ¼å¼åŒ–æ•™å¸ˆè¾“å…¥"""
        context = f"Question: {problem}\n\n"
        for role, content in history:
            context += f"{role}: {content}\n\n" # ä¸‹é¢çš„è‹±æ–‡ï¼šè¯·æ ¹æ®ä»¥ä¸Šå¯¹è¯ç»§ç»­å¼•å¯¼å­¦ç”Ÿè§£é¢˜:
        context += "Please continue guiding students through the problem-solving process based on the above dialogue:"
        return context

    def _format_student_input(self, problem, history):
        """æ ¼å¼åŒ–å­¦ç”Ÿè¾“å…¥"""
        context = f"Raw question: {problem}\n\nChat history:\n"
        for role, content in history:
            context += f"{role}: {content}\n\n"
        context += "Please continue solving the problem or respond to the teacher's instructions:"
        return context

    def _teacher_end_dialogue(self, teacher_response):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»“æŸå¯¹è¯"""
        end_phrases = ["å®Œæˆ", "finish"]
        return any(phrase in teacher_response.lower() for phrase in end_phrases)

    def _student_end_dialogue(self, student_response, problem):
        """ç®€å•åˆ¤æ–­å­¦ç”Ÿæ˜¯å¦å¾—å‡ºæ­£ç¡®ç­”æ¡ˆ"""
        # è¿™é‡Œå¯ä»¥é›†æˆæ›´å¤æ‚çš„ç­”æ¡ˆéªŒè¯é€»è¾‘
        math_indicators = ["ç­”æ¡ˆæ˜¯", "ç»“æžœä¸º", "ç­‰äºŽ", "=", "final answer is"]
        return any(indicator in student_response for indicator in math_indicators)

    def _get_final_answer(self):
        """èŽ·å–æœ€ç»ˆç­”æ¡ˆ"""
        if self.dialogue_history:
            return self.dialogue_history[-1][1]
        return ""

    def agent_response_invoke(self, user_input, **kwargs):
        self.response = self.agent.invoke({
            "messages": [{"role": "user", "content": user_input}]
        }, config=self.agent_config, context=self.context, **kwargs)

    def agent_response_stream(self, user_input, **kwargs):
        for chunk in self.agent.stream({
            "messages": [{"role": "user", "content": user_input}]
        }, config=self.agent_config, context=self.context, stream_mode="values", **kwargs):
            latest_message = chunk["messages"][-1]
            if latest_message.content:
                print(f"Agent: {latest_message.content}")
            elif latest_message.tool_calls:
                print(f"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}")

    def agent_output(self):
        for i in self.response['messages']:
            print(f"{type(i)}: {i.content}")


# å…¶ä»–ç±»ä¿æŒä¸å˜...
class CustomState(AgentState):
    user_preferences: dict


class CustomMiddleware(AgentMiddleware):
    state_schema = CustomState

    def before_model(self, state: CustomState, runtime):
        if state.user_preferences.get("style") == "technical":
            return {"system_prompt": "Provide detailed technical explanations with specifications."}
        else:
            return {"system_prompt": "Explain concepts in simple, easy-to-understand terms."}

    def before_tool_call(self, state: CustomState, runtime, tool_name):
        if state.user_preferences.get("verbosity") == "detailed":
            return "technical_search"
        else:
            return "simple_search"


class MiddlewareFunc(object):
    def __init__(self, basic_model, advanced_model):
        self.basic_model = basic_model
        self.advanced_model = advanced_model

    def middleware_handle_tool_errors(self) -> Callable:
        @wrap_tool_call
        def handle_tool_errors(request, handler):
            try:
                return handler(request)
            except Exception as e:
                return ToolMessage(
                    content=f"Tool error: Please check your input and try again. ({str(e)})",
                    tool_call_id=request.tool_call["id"]
                )

        return handle_tool_errors

    def middleware_dynamic_model_selection(self) -> Callable:
        @wrap_model_call
        def dynamic_model_middleware(request: ModelRequest, handler) -> ModelResponse:
            messages = request.state.get("messages", [])
            message_count = len(messages)
            print(f"Debug: Current message count = {message_count}")

            if message_count >= 2:
                user_content = ""
                for msg in reversed(messages):
                    if isinstance(msg, HumanMessage):
                        user_content = msg.content
                        break
                complex_keywords = ['solution', 'problem', 'explain', 'analyze', 'how to', 'why', 'compare']
                is_complex = any(keyword in user_content.lower() for keyword in complex_keywords)
                if is_complex and self.advanced_model:
                    model = self.advanced_model
                    model_name = self.advanced_model.model_name
                    print(f'ðŸ”€ Selected ADVANCED model for complex query: {model_name}')
                else:
                    model = self.basic_model
                    model_name = self.basic_model.model_name
                    print(f'ðŸ”€ Selected BASIC model: {model_name}')
            else:
                model = self.basic_model
                model_name = self.basic_model.model_name
                print(f'ðŸ”€ Selected BASIC model (first message): {model_name}')
            request.model = model
            return handler(request)

        return dynamic_model_middleware

    def middleware_user_role_prompt(self) -> Callable:
        @dynamic_prompt
        def user_role_prompt(request: ModelRequest) -> str:
            user_role = request.runtime.context.user_role
            if user_role == "expert":
                return EXPECT_PROMPT
            elif user_role == "beginner":
                return BEGINNER_PROMPT
            return BASE_PROMPT

        return user_role_prompt