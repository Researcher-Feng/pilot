import datetime
from typing import Optional, Dict, Any

class SmartSummaryMemory:
    """æ™ºèƒ½å¯¹è¯æ‘˜è¦å†…å­˜ç®¡ç†"""

    def __init__(self, llm=None, max_turns=10, max_token_limit=2000, enabled=False, debug_mode=False):
        self.debug_mode = debug_mode
        self.enabled = enabled
        self.max_turns = max_turns
        self.max_token_limit = max_token_limit
        self.llm = llm
        self.conversation_history = []
        self.summary_history = []  # å­˜å‚¨å†å²æ‘˜è¦
        self.turn_count = 0
        self.current_summary = ""

    def add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²"""
        if not self.enabled:
            return

        self.conversation_history.append({"role": role, "content": content})
        self.turn_count += 1

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ‘˜è¦
        if self._should_generate_summary():
            self._generate_summary()

    def _should_generate_summary(self):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ‘˜è¦"""
        if not self.enabled:
            return False

        # åŸºäºè½®æ¬¡åˆ¤æ–­
        if self.turn_count >= self.max_turns:
            return True

        # åŸºäºtokenæ•°é‡åˆ¤æ–­ï¼ˆç®€å•ä¼°ç®—ï¼‰
        total_chars = sum(len(msg["content"]) for msg in self.conversation_history)
        estimated_tokens = total_chars // 4  # ç®€å•ä¼°ç®—ï¼š1 token â‰ˆ 4 characters
        if estimated_tokens > self.max_token_limit:
            return True

        return False

    def _generate_summary(self):
        """ç”Ÿæˆå¯¹è¯æ‘˜è¦"""
        if not self.enabled or not self.llm:
            return

        try:
            # æ„å»ºæ‘˜è¦æç¤ºè¯
            conversation_text = "\n".join(
                [f"{msg['role']}: {msg['content']}" for msg in self.conversation_history]
            )

            summary_prompt = f"""Please summarize the key information from this math tutoring conversation, focusing on:

1. The main math problem being discussed
2. Student's current approach and difficulties
3. Teacher's guidance and key questions asked
4. Important intermediate steps and concepts
5. Current progress toward solution

Conversation:
{conversation_text}

Provide a concise but informative summary in English:"""

            # è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦
            if hasattr(self.llm, 'invoke'):
                response = self.llm.invoke(summary_prompt)
                summary = response.content if hasattr(response, 'content') else str(response)
            else:
                # ç®€åŒ–è°ƒç”¨
                summary = "Summary: Math problem discussion in progress"

            self.current_summary = summary
            self.summary_history.append({
                "turn_count": self.turn_count,
                "summary": summary,
                "timestamp": datetime.datetime.now().isoformat()
            })

            # ä¿ç•™æœ€è¿‘å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡
            keep_recent = min(3, len(self.conversation_history))
            self.conversation_history = self.conversation_history[-keep_recent:]
            self.turn_count = keep_recent

            if self.debug_mode:
                logger.info(f"ğŸ“ å·²ç”Ÿæˆå¯¹è¯æ‘˜è¦ (ç¬¬{len(self.summary_history)}æ¬¡æ‘˜è¦)")
                logger.info(f"Summary: {summary[:200]}...")

        except Exception as e:
            logger.warning(f"âŒ ç”Ÿæˆæ‘˜è¦æ—¶å‡ºé”™: {e}")
            self.current_summary = f"Conversation history: {len(self.conversation_history)} turns about math problem"

    def get_context(self):
        """è·å–å½“å‰ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«æ‘˜è¦ï¼‰"""
        if not self.enabled:
            return ""

        context_parts = []

        # æ·»åŠ å½“å‰æ‘˜è¦
        if self.current_summary:
            context_parts.append(f"Previous Conversation Summary:\n{self.current_summary}")

        # æ·»åŠ æœ€è¿‘å¯¹è¯å†å²
        recent_messages = self.conversation_history[-3:]  # ä¿ç•™æœ€è¿‘3è½®
        if recent_messages:
            recent_text = "\n".join(
                [f"{msg['role']}: {msg['content']}" for msg in recent_messages]
            )
            context_parts.append(f"Recent Dialogue:\n{recent_text}")

        return "\n\n".join(context_parts) if context_parts else ""

    def clear(self):
        """æ¸…ç©ºå†…å­˜"""
        self.conversation_history.clear()
        self.summary_history.clear()
        self.turn_count = 0
        self.current_summary = ""

    def get_stats(self):
        """è·å–å†…å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "enabled": self.enabled,
            "total_turns": self.turn_count,
            "conversation_history_count": len(self.conversation_history),
            "summary_history_count": len(self.summary_history),
            "current_summary_length": len(self.current_summary)
        }


class SummaryConfig:
    """æ‘˜è¦é…ç½®ç±»"""
    def __init__(self, enabled=False, max_turns=10, max_token_limit=2000, summary_model=None):
        self.enabled = enabled
        self.max_turns = max_turns
        self.max_token_limit = max_token_limit
        self.summary_model = summary_model  # ä¸“é—¨ç”¨äºæ‘˜è¦çš„æ¨¡å‹é…ç½®


class DialogueRecord:
    """å¯¹è¯è®°å½•ç±»"""

    def __init__(self, problem: str, correct_answer: str, debug_mode: bool = False):
        self.problem = problem
        self.correct_answer = correct_answer
        self.debug_mode = debug_mode
        self.turns = []
        self.final_student_answer = ""
        self.first_correct = False
        self.correct = False
        self.leaked_answer = False
        self.parallel_thinking_count = 0
        self.thinking_paths_count = 0
        self.total_turns = 0

    def add_turn(self, turn_data: Dict[str, Any]):
        """æ·»åŠ ä¸€è½®å¯¹è¯è®°å½•"""
        self.turns.append(turn_data)
        self.total_turns = len(self.turns)

    def analyze_student_response(self, response: str):
        """åˆ†æå­¦ç”Ÿå›å¤"""
        # ç»Ÿè®¡å¹¶è¡Œæ€è€ƒæ ‡ç­¾
        parallel_count = response.count('<Parallel')
        self.parallel_thinking_count += parallel_count

        # ç»Ÿè®¡æ€è€ƒè·¯å¾„æ ‡ç­¾
        path_count = response.count('<Path')
        self.thinking_paths_count += path_count

        return parallel_count, path_count

    def check_answer_leakage(self, teacher_response: str, answer_num: str):
        """æ£€æŸ¥æ•™å¸ˆæ˜¯å¦æ³„éœ²ç­”æ¡ˆ"""
        # ç®€å•çš„ç­”æ¡ˆæ³„éœ²æ£€æµ‹é€»è¾‘
        leakage_indicators = [
            "Final Answer: " + self.correct_answer,
            "the result is " + self.correct_answer,
            "equals to " + self.correct_answer,
            "= " + self.correct_answer,
            answer_num
        ]

        leakage_detected = any(
            indicator.lower() in teacher_response.lower()
            for indicator in leakage_indicators
            if indicator.strip()
        )

        if leakage_detected:
            self.leaked_answer = True

        return leakage_detected

    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "problem": self.problem,
            "correct_answer": self.correct_answer,
            "final_student_answer": self.final_student_answer,
            "correct": self.correct,
            "leaked_answer": self.leaked_answer,
            "parallel_thinking_count": self.parallel_thinking_count,
            "thinking_paths_count": self.thinking_paths_count,
            "total_turns": self.total_turns,
            "turns": self.turns
        }
